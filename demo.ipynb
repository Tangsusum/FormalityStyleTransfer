{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "d38bf1c1a78eb9e2f1036051b7ddac948ef9f78e1358a3ad599c783230a4575e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import nltk\n",
    "import ssl\n",
    "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
    "from Evaluation.evaluationMetric import ngramsScore\n",
    "from Evaluation.postProcessing import postProcessing\n",
    "from Evaluation.selection import set_seed, getMaxNgram, getSelected, preProcessing, getVector\n",
    "\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('./mymodel')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (\"device \",device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For bi-directional formality style transfer model, select the translation direction by feeding in the correct prefix \n",
    "\"\"\"\n",
    "\n",
    "sentence = \"designed to simplify our organization and increase our agility to better serve our clients at scale.\"\n",
    "\n",
    "text =  \"formal2informal: \" + sentence\n",
    "# text =  \"informal2formal: \" + sentence\n",
    "\n",
    "max_len = 256\n",
    "\n",
    "encoding = tokenizer.encode_plus(text, padding=\"max_length\", return_tensors=\"pt\")\n",
    "input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "beam_outputs = model.generate(\n",
    "    input_ids=input_ids, attention_mask=attention_masks,\n",
    "    do_sample=True,\n",
    "    max_length=256,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    early_stopping=True,\n",
    "    num_return_sequences=10\n",
    ")\n",
    "\n",
    "\n",
    "print (\"\\nOriginal Sentence ::\")\n",
    "print (sentence)\n",
    "print (\"\\n\")\n",
    "print (\"Translated Sentences :: \")\n",
    "\n",
    "# Get ngrams for sentence selection\n",
    "ngrams = []\n",
    "sentences = []\n",
    "final_outputs =[]\n",
    "\n",
    "for beam_output in beam_outputs:\n",
    "    sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "    if sent.lower() != sentence.lower() and sent not in final_outputs:\n",
    "        final_outputs.append(sent)\n",
    "\n",
    "# Get word vector distance \n",
    "distances = getVector(sentence, final_outputs)\n",
    "\n",
    "for i, final_output in enumerate(final_outputs):\n",
    "    ngrams.append(ngramsScore(sentence,final_output))\n",
    "    print(\"{}: {} ngrams={} dist={}\".format(i, final_output, ngramsScore(sentence, final_output), distances[i]))\n",
    "    \n",
    "\n",
    "index, maxNgram = getMaxNgram(sorted(ngrams, reverse=True), 1.1)\n",
    "print(\"\\n\")\n",
    "print('Selected Sentence (ngrams w/o threshold):')\n",
    "print(final_outputs[ngrams.index(maxNgram)])\n",
    "\n",
    "index, maxNgram = getMaxNgram(sorted(ngrams, reverse=True), 0.8)\n",
    "print(\"\\n\")\n",
    "print('Selected Sentence (ngrams w/ threshold):')\n",
    "print(final_outputs[ngrams.index(maxNgram)])\n",
    "\n",
    "print(\"\\n\")\n",
    "dist, ngram, selected_sentence = getSelected(ngrams, distances, final_outputs, 0.8)\n",
    "print('Selected Sentence (ngrams + wordVector):')\n",
    "print(selected_sentence)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Post-processed sentence:\")\n",
    "print(postProcessing(selected_sentence))"
   ]
  }
 ]
}